"""
Agent 5 - Test Agent for Processing Pipeline

This is a scaffolding agent for testing the agent processing pipeline.
Functionality will be added between status states.
"""
import asyncio
import json
import time
from typing import Optional, Dict, Any
from app.services.websocket_manager import WebSocketManager
from app.services.storage import StorageService


async def agent_5_process(
    websocket_manager: WebSocketManager,
    user_id: str,
    session_id: str,
    supersessionid: str,
    storage_service: Optional[StorageService] = None,
    pipeline_data: Optional[Dict[str, Any]] = None
):
    """
    Agent5: Third and final agent in the processing pipeline.

    This is scaffolding - functionality will be added between status states.

    Args:
        websocket_manager: WebSocket manager for status updates
        user_id: User identifier
        session_id: Session identifier
        supersessionid: Super session identifier (generated by Agent2)
        storage_service: Storage service for S3 operations
        pipeline_data: All pipeline data including:
            - agent2_data: Data from Agent2 (template_id, diagram_id, script_id, etc.)
            - script: The script with hook, concept, process, conclusion
            - voice: TTS voice used
            - audio_option: Audio generation option
            - audio_data: Audio generation results from Agent4
    """
    # Initialize storage service if not provided
    if storage_service is None:
        storage_service = StorageService()
    
    # Helper function to create JSON status file in S3
    async def create_status_json(agent_number: str, status: str, status_data: dict):
        """Create a JSON file in S3 with status data."""
        if not storage_service.s3_client:
            return  # Skip if storage not configured
        
        timestamp = int(time.time() * 1000)  # Milliseconds timestamp
        filename = f"agent_{agent_number}_{status}_{timestamp}.json"
        s3_key = f"scaffold_test/{user_id}/{supersessionid}/{filename}"
        
        try:
            json_content = json.dumps(status_data, indent=2).encode('utf-8')
            storage_service.s3_client.put_object(
                Bucket=storage_service.bucket_name,
                Key=s3_key,
                Body=json_content,
                ContentType='application/json'
            )
        except Exception as e:
            # Log but don't fail the pipeline if JSON creation fails
            print(f"Failed to create status JSON file: {e}")
    
    video_url = None
    
    try:
        # Report starting status
        status_data = {
            "agentnumber": "Agent5",
            "userID": user_id,
            "sessionID": session_id,
            "supersessionID": supersessionid,
            "status": "starting",
            "timestamp": int(time.time() * 1000)
        }
        await websocket_manager.send_progress(session_id, status_data)
        await create_status_json("5", "starting", status_data)
        
        # Wait 2 seconds
        await asyncio.sleep(2)
        
        # TODO: Add initialization/preparation logic here
        
        # Report processing status
        status_data = {
            "agentnumber": "Agent5",
            "userID": user_id,
            "sessionID": session_id,
            "supersessionID": supersessionid,
            "status": "processing",
            "timestamp": int(time.time() * 1000)
        }
        await websocket_manager.send_progress(session_id, status_data)
        await create_status_json("5", "processing", status_data)
        
        # Copy video file from scaffold_test/ to scaffold_test/{user_id}/{supersessionid}/
        if storage_service.s3_client:
            try:
                source_key = "scaffold_test/final_video_dae6d4f1.mp4"
                dest_key = f"scaffold_test/{user_id}/{supersessionid}/final_video_dae6d4f1.mp4"
                
                # Copy the file
                storage_service.copy_file(source_key, dest_key)
                
                # Generate presigned URL for easy frontend access (1 hour expiration)
                video_url = storage_service.generate_presigned_url(dest_key, expires_in=3600)
            except Exception as e:
                print(f"Failed to copy video file: {e}")
                # Continue even if video copy fails
                video_url = None
        
        # Wait 2 seconds
        await asyncio.sleep(2)
        
        # TODO: Add main agent work here (e.g., final processing, output generation)
        
        # Report finished status with video URL
        status_data = {
            "agentnumber": "Agent5",
            "userID": user_id,
            "sessionID": session_id,
            "supersessionID": supersessionid,
            "status": "finished",
            "timestamp": int(time.time() * 1000)
        }
        
        if video_url:
            status_data["videoUrl"] = video_url
        
        await websocket_manager.send_progress(session_id, status_data)
        await create_status_json("5", "finished", status_data)
        
        # TODO: Add cleanup/finalization logic here
        
    except Exception as e:
        # Report error status and stop pipeline
        error_data = {
            "agentnumber": "Agent5",
            "userID": user_id,
            "sessionID": session_id,
            "supersessionID": supersessionid,
            "status": "error",
            "error": str(e),
            "reason": f"Agent5 failed: {type(e).__name__}",
            "timestamp": int(time.time() * 1000)
        }
        await websocket_manager.send_progress(session_id, error_data)
        await create_status_json("5", "error", error_data)
        raise  # Stop pipeline on error

